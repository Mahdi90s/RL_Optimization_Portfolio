{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shimmy>=2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:41:35.650197: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750714895.695852   67985 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750714895.709597   67985 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-23 22:41:35.743873: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "import torch\n",
    "import gym\n",
    "from envs.portfolio_env import PortfolioEnv\n",
    "import random\n",
    "\n",
    "from stable_baselines3 import A2C  # we use A2C because it’s a type of policy gradient\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67985/1496721472.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(tickers=assets, start= start_date , end= end_date, interval='1d')\n",
      "[*********************100%***********************]  10 of 10 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>HSBC</th>\n",
       "      <th>IBM</th>\n",
       "      <th>JPM</th>\n",
       "      <th>META</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>...</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>HSBC</th>\n",
       "      <th>IBM</th>\n",
       "      <th>JPM</th>\n",
       "      <th>META</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>37.617863</td>\n",
       "      <td>76.956497</td>\n",
       "      <td>52.419628</td>\n",
       "      <td>27.954203</td>\n",
       "      <td>82.193153</td>\n",
       "      <td>82.408607</td>\n",
       "      <td>134.939713</td>\n",
       "      <td>94.945496</td>\n",
       "      <td>3.377545</td>\n",
       "      <td>20.674667</td>\n",
       "      <td>...</td>\n",
       "      <td>148158800</td>\n",
       "      <td>159662000</td>\n",
       "      <td>31868000</td>\n",
       "      <td>2565000</td>\n",
       "      <td>4434935</td>\n",
       "      <td>15670900</td>\n",
       "      <td>28146200</td>\n",
       "      <td>35329300</td>\n",
       "      <td>508752000</td>\n",
       "      <td>174879000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>33.870842</td>\n",
       "      <td>75.014000</td>\n",
       "      <td>50.967831</td>\n",
       "      <td>27.646486</td>\n",
       "      <td>80.552269</td>\n",
       "      <td>81.237442</td>\n",
       "      <td>131.021210</td>\n",
       "      <td>91.452660</td>\n",
       "      <td>3.173483</td>\n",
       "      <td>20.024000</td>\n",
       "      <td>...</td>\n",
       "      <td>365248800</td>\n",
       "      <td>139512000</td>\n",
       "      <td>41960000</td>\n",
       "      <td>1479400</td>\n",
       "      <td>4546648</td>\n",
       "      <td>16286400</td>\n",
       "      <td>22717900</td>\n",
       "      <td>42579100</td>\n",
       "      <td>705552000</td>\n",
       "      <td>104478000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>35.316753</td>\n",
       "      <td>78.769501</td>\n",
       "      <td>53.582146</td>\n",
       "      <td>28.453382</td>\n",
       "      <td>83.698486</td>\n",
       "      <td>84.232300</td>\n",
       "      <td>137.197311</td>\n",
       "      <td>95.706055</td>\n",
       "      <td>3.376801</td>\n",
       "      <td>21.179333</td>\n",
       "      <td>...</td>\n",
       "      <td>234428400</td>\n",
       "      <td>183652000</td>\n",
       "      <td>46022000</td>\n",
       "      <td>3060900</td>\n",
       "      <td>4683779</td>\n",
       "      <td>16935200</td>\n",
       "      <td>29002100</td>\n",
       "      <td>44060600</td>\n",
       "      <td>585620000</td>\n",
       "      <td>110911500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-07</th>\n",
       "      <td>35.238159</td>\n",
       "      <td>81.475502</td>\n",
       "      <td>53.475292</td>\n",
       "      <td>28.070450</td>\n",
       "      <td>84.290596</td>\n",
       "      <td>84.290848</td>\n",
       "      <td>137.296783</td>\n",
       "      <td>95.828110</td>\n",
       "      <td>3.555571</td>\n",
       "      <td>22.330667</td>\n",
       "      <td>...</td>\n",
       "      <td>219111200</td>\n",
       "      <td>159864000</td>\n",
       "      <td>47446000</td>\n",
       "      <td>2212300</td>\n",
       "      <td>3923755</td>\n",
       "      <td>15430700</td>\n",
       "      <td>20089300</td>\n",
       "      <td>35656100</td>\n",
       "      <td>709160000</td>\n",
       "      <td>113268000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-08</th>\n",
       "      <td>35.909889</td>\n",
       "      <td>82.829002</td>\n",
       "      <td>53.944969</td>\n",
       "      <td>28.145664</td>\n",
       "      <td>85.489136</td>\n",
       "      <td>84.131897</td>\n",
       "      <td>141.752335</td>\n",
       "      <td>96.522949</td>\n",
       "      <td>3.467054</td>\n",
       "      <td>22.356667</td>\n",
       "      <td>...</td>\n",
       "      <td>164101200</td>\n",
       "      <td>177628000</td>\n",
       "      <td>35414000</td>\n",
       "      <td>2888300</td>\n",
       "      <td>4982726</td>\n",
       "      <td>13578800</td>\n",
       "      <td>26263800</td>\n",
       "      <td>31514400</td>\n",
       "      <td>786016000</td>\n",
       "      <td>105127500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-24</th>\n",
       "      <td>257.578674</td>\n",
       "      <td>229.050003</td>\n",
       "      <td>195.647552</td>\n",
       "      <td>47.340084</td>\n",
       "      <td>221.451187</td>\n",
       "      <td>239.589233</td>\n",
       "      <td>606.742920</td>\n",
       "      <td>437.647400</td>\n",
       "      <td>140.197372</td>\n",
       "      <td>462.279999</td>\n",
       "      <td>...</td>\n",
       "      <td>23234700</td>\n",
       "      <td>15007500</td>\n",
       "      <td>10403300</td>\n",
       "      <td>309000</td>\n",
       "      <td>1186200</td>\n",
       "      <td>3729100</td>\n",
       "      <td>4726100</td>\n",
       "      <td>7164500</td>\n",
       "      <td>105157000</td>\n",
       "      <td>59551800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-26</th>\n",
       "      <td>258.396667</td>\n",
       "      <td>227.050003</td>\n",
       "      <td>195.138763</td>\n",
       "      <td>47.349697</td>\n",
       "      <td>221.924850</td>\n",
       "      <td>240.409912</td>\n",
       "      <td>602.350220</td>\n",
       "      <td>436.432068</td>\n",
       "      <td>139.907410</td>\n",
       "      <td>454.130005</td>\n",
       "      <td>...</td>\n",
       "      <td>27237100</td>\n",
       "      <td>16146700</td>\n",
       "      <td>12046600</td>\n",
       "      <td>516300</td>\n",
       "      <td>3286500</td>\n",
       "      <td>4451800</td>\n",
       "      <td>6081400</td>\n",
       "      <td>8194200</td>\n",
       "      <td>116205600</td>\n",
       "      <td>76366400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-27</th>\n",
       "      <td>254.974930</td>\n",
       "      <td>223.750000</td>\n",
       "      <td>192.305450</td>\n",
       "      <td>47.378536</td>\n",
       "      <td>219.842682</td>\n",
       "      <td>238.462036</td>\n",
       "      <td>598.816040</td>\n",
       "      <td>428.881104</td>\n",
       "      <td>136.987869</td>\n",
       "      <td>431.660004</td>\n",
       "      <td>...</td>\n",
       "      <td>42355300</td>\n",
       "      <td>27367100</td>\n",
       "      <td>18891400</td>\n",
       "      <td>1088100</td>\n",
       "      <td>1810800</td>\n",
       "      <td>5730200</td>\n",
       "      <td>8084200</td>\n",
       "      <td>18117700</td>\n",
       "      <td>170582600</td>\n",
       "      <td>82666800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-30</th>\n",
       "      <td>251.593094</td>\n",
       "      <td>221.300003</td>\n",
       "      <td>190.789032</td>\n",
       "      <td>47.590000</td>\n",
       "      <td>217.346039</td>\n",
       "      <td>236.632812</td>\n",
       "      <td>590.260254</td>\n",
       "      <td>423.202911</td>\n",
       "      <td>137.467804</td>\n",
       "      <td>417.410004</td>\n",
       "      <td>...</td>\n",
       "      <td>35557500</td>\n",
       "      <td>28321200</td>\n",
       "      <td>14264700</td>\n",
       "      <td>1344500</td>\n",
       "      <td>2095600</td>\n",
       "      <td>5723800</td>\n",
       "      <td>7025900</td>\n",
       "      <td>13158700</td>\n",
       "      <td>167734700</td>\n",
       "      <td>64941000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31</th>\n",
       "      <td>249.817383</td>\n",
       "      <td>219.389999</td>\n",
       "      <td>188.853622</td>\n",
       "      <td>47.541943</td>\n",
       "      <td>216.931580</td>\n",
       "      <td>237.018433</td>\n",
       "      <td>584.539795</td>\n",
       "      <td>419.885681</td>\n",
       "      <td>134.268326</td>\n",
       "      <td>403.839996</td>\n",
       "      <td>...</td>\n",
       "      <td>39480700</td>\n",
       "      <td>24819700</td>\n",
       "      <td>17466900</td>\n",
       "      <td>768200</td>\n",
       "      <td>2270200</td>\n",
       "      <td>4871000</td>\n",
       "      <td>6019500</td>\n",
       "      <td>13246500</td>\n",
       "      <td>155659200</td>\n",
       "      <td>76825100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1510 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price            Close                                                 \\\n",
       "Ticker            AAPL        AMZN       GOOGL       HSBC         IBM   \n",
       "Date                                                                    \n",
       "2019-01-02   37.617863   76.956497   52.419628  27.954203   82.193153   \n",
       "2019-01-03   33.870842   75.014000   50.967831  27.646486   80.552269   \n",
       "2019-01-04   35.316753   78.769501   53.582146  28.453382   83.698486   \n",
       "2019-01-07   35.238159   81.475502   53.475292  28.070450   84.290596   \n",
       "2019-01-08   35.909889   82.829002   53.944969  28.145664   85.489136   \n",
       "...                ...         ...         ...        ...         ...   \n",
       "2024-12-24  257.578674  229.050003  195.647552  47.340084  221.451187   \n",
       "2024-12-26  258.396667  227.050003  195.138763  47.349697  221.924850   \n",
       "2024-12-27  254.974930  223.750000  192.305450  47.378536  219.842682   \n",
       "2024-12-30  251.593094  221.300003  190.789032  47.590000  217.346039   \n",
       "2024-12-31  249.817383  219.389999  188.853622  47.541943  216.931580   \n",
       "\n",
       "Price                                                                   ...  \\\n",
       "Ticker             JPM        META        MSFT        NVDA        TSLA  ...   \n",
       "Date                                                                    ...   \n",
       "2019-01-02   82.408607  134.939713   94.945496    3.377545   20.674667  ...   \n",
       "2019-01-03   81.237442  131.021210   91.452660    3.173483   20.024000  ...   \n",
       "2019-01-04   84.232300  137.197311   95.706055    3.376801   21.179333  ...   \n",
       "2019-01-07   84.290848  137.296783   95.828110    3.555571   22.330667  ...   \n",
       "2019-01-08   84.131897  141.752335   96.522949    3.467054   22.356667  ...   \n",
       "...                ...         ...         ...         ...         ...  ...   \n",
       "2024-12-24  239.589233  606.742920  437.647400  140.197372  462.279999  ...   \n",
       "2024-12-26  240.409912  602.350220  436.432068  139.907410  454.130005  ...   \n",
       "2024-12-27  238.462036  598.816040  428.881104  136.987869  431.660004  ...   \n",
       "2024-12-30  236.632812  590.260254  423.202911  137.467804  417.410004  ...   \n",
       "2024-12-31  237.018433  584.539795  419.885681  134.268326  403.839996  ...   \n",
       "\n",
       "Price          Volume                                                   \\\n",
       "Ticker           AAPL       AMZN     GOOGL     HSBC      IBM       JPM   \n",
       "Date                                                                     \n",
       "2019-01-02  148158800  159662000  31868000  2565000  4434935  15670900   \n",
       "2019-01-03  365248800  139512000  41960000  1479400  4546648  16286400   \n",
       "2019-01-04  234428400  183652000  46022000  3060900  4683779  16935200   \n",
       "2019-01-07  219111200  159864000  47446000  2212300  3923755  15430700   \n",
       "2019-01-08  164101200  177628000  35414000  2888300  4982726  13578800   \n",
       "...               ...        ...       ...      ...      ...       ...   \n",
       "2024-12-24   23234700   15007500  10403300   309000  1186200   3729100   \n",
       "2024-12-26   27237100   16146700  12046600   516300  3286500   4451800   \n",
       "2024-12-27   42355300   27367100  18891400  1088100  1810800   5730200   \n",
       "2024-12-30   35557500   28321200  14264700  1344500  2095600   5723800   \n",
       "2024-12-31   39480700   24819700  17466900   768200  2270200   4871000   \n",
       "\n",
       "Price                                                 \n",
       "Ticker          META      MSFT       NVDA       TSLA  \n",
       "Date                                                  \n",
       "2019-01-02  28146200  35329300  508752000  174879000  \n",
       "2019-01-03  22717900  42579100  705552000  104478000  \n",
       "2019-01-04  29002100  44060600  585620000  110911500  \n",
       "2019-01-07  20089300  35656100  709160000  113268000  \n",
       "2019-01-08  26263800  31514400  786016000  105127500  \n",
       "...              ...       ...        ...        ...  \n",
       "2024-12-24   4726100   7164500  105157000   59551800  \n",
       "2024-12-26   6081400   8194200  116205600   76366400  \n",
       "2024-12-27   8084200  18117700  170582600   82666800  \n",
       "2024-12-30   7025900  13158700  167734700   64941000  \n",
       "2024-12-31   6019500  13246500  155659200   76825100  \n",
       "\n",
       "[1510 rows x 50 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets = ['NVDA', 'AAPL', 'AMZN', 'JPM', 'IBM', 'MSFT', 'TSLA', 'GOOGL', 'META', 'HSBC']\n",
    "start_date ='2019-01-01'\n",
    "end_date = '2025-01-01'\n",
    " \n",
    "df = yf.download(tickers=assets, start= start_date , end= end_date, interval='1d')\n",
    "\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67985/3544417225.py:1: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  sta = df.stack()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price       Date Ticker      Close       High        Low       Open     Volume\n",
      "0     2019-01-02   AAPL  37.617863  37.839398  36.738873  36.896092  148158800\n",
      "1     2019-01-02   AMZN  76.956497  77.667999  73.046501  73.260002  159662000\n",
      "2     2019-01-02  GOOGL  52.419628  52.723307  50.958390  51.053819   31868000\n",
      "3     2019-01-02   HSBC  27.954203  27.974716  27.523401  27.605457    2565000\n",
      "4     2019-01-02    IBM  82.193153  82.742487  79.681917  79.910209    4434935\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15100 entries, 0 to 15099\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   Date    15100 non-null  datetime64[ns]\n",
      " 1   Ticker  15100 non-null  object        \n",
      " 2   Close   15100 non-null  float64       \n",
      " 3   High    15100 non-null  float64       \n",
      " 4   Low     15100 non-null  float64       \n",
      " 5   Open    15100 non-null  float64       \n",
      " 6   Volume  15100 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), object(1)\n",
      "memory usage: 825.9+ KB\n",
      "None\n",
      "Price                           Date         Close          High  \\\n",
      "count                          15100  15100.000000  15100.000000   \n",
      "mean   2021-12-30 20:45:27.417218816    141.743575    143.478385   \n",
      "min              2019-01-02 00:00:00      3.173483      3.351262   \n",
      "25%              2020-07-01 00:00:00     69.599958     70.286712   \n",
      "50%              2021-12-29 12:00:00    126.796478    128.431442   \n",
      "75%              2023-07-03 00:00:00    186.449627    188.472036   \n",
      "max              2024-12-31 00:00:00    631.122498    636.828448   \n",
      "std                              NaN    103.097830    104.411764   \n",
      "\n",
      "Price           Low          Open        Volume  \n",
      "count  15100.000000  15100.000000  1.510000e+04  \n",
      "mean     139.903254    141.696047  8.428495e+07  \n",
      "min        3.166045      3.239190  3.090000e+05  \n",
      "25%       68.352691     69.331199  1.038366e+07  \n",
      "50%      125.276100    126.916101  2.936965e+07  \n",
      "75%      183.860539    186.309104  8.229180e+07  \n",
      "max      625.666039    629.945457  2.511528e+09  \n",
      "std      101.726819    103.107718  1.456788e+08  \n",
      "Price\n",
      "Date      datetime64[ns]\n",
      "Ticker            object\n",
      "Close            float64\n",
      "High             float64\n",
      "Low              float64\n",
      "Open             float64\n",
      "Volume             int64\n",
      "dtype: object\n",
      "Price\n",
      "Date      0\n",
      "Ticker    0\n",
      "Close     0\n",
      "High      0\n",
      "Low       0\n",
      "Open      0\n",
      "Volume    0\n",
      "dtype: int64\n",
      "0\n",
      "15099\n",
      "Row False\n",
      "col False\n"
     ]
    }
   ],
   "source": [
    "sta = df.stack()\n",
    "\n",
    "df_flt = sta.reset_index()\n",
    "is_multi_index = isinstance(df_flt.index, pd.MultiIndex)  \n",
    "is_multi_col= isinstance(df_flt.columns, pd.MultiIndex)\n",
    "\n",
    "print (df_flt.head())\n",
    "print (df_flt.info())\n",
    "print (df_flt.describe())\n",
    "print (df_flt.dtypes)\n",
    "print (df_flt.isna().sum())\n",
    "print(df_flt.index.to_series().min())\n",
    "print(df_flt.index.to_series().max())\n",
    "print ('Row', is_multi_index)\n",
    "print ('col', is_multi_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for symbol in assets:\n",
    "#     df = yf.download(tickers=symbol, start= start_date , end= end_date, interval='1d')\n",
    "#     sta = df.stack()\n",
    "#     df_flt = sta.reset_index()\n",
    "#     df_flt.to_csv(f'/home/micheal/Documents/Python_Library/RL_Optimization_Portfolio/data/raw/{symbol}_daily.CSV')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Ticker      Close       High        Low       Open     Volume\n",
      "Date                                                                    \n",
      "2019-01-02   AAPL  37.617844  37.839379  36.738855  36.896073  148158800\n",
      "2019-01-03   AAPL  33.870834  34.711709  33.825574  34.297226  365248800\n",
      "2019-01-04   AAPL  35.316757  35.385840  34.254350  34.428241  234428400\n",
      "2019-01-07   AAPL  35.238152  35.452541  34.754589  35.421573  219111200\n",
      "2019-01-08   AAPL  35.909897  36.164781  35.378693  35.626428  164101200\n",
      "Index(['Ticker', 'Close', 'High', 'Low', 'Open', 'Volume'], dtype='object')\n",
      "           Ticker\n",
      "Date             \n",
      "2019-01-02   AAPL\n",
      "2019-01-03   AAPL\n",
      "2019-01-04   AAPL\n",
      "2019-01-07   AAPL\n",
      "2019-01-08   AAPL\n",
      "...           ...\n",
      "2024-12-24   MSFT\n",
      "2024-12-26   MSFT\n",
      "2024-12-27   MSFT\n",
      "2024-12-30   MSFT\n",
      "2024-12-31   MSFT\n",
      "\n",
      "[3020 rows x 1 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3020 entries, 2019-01-02 to 2024-12-31\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Ticker  3020 non-null   object \n",
      " 1   Close   3020 non-null   float64\n",
      " 2   High    3020 non-null   float64\n",
      " 3   Low     3020 non-null   float64\n",
      " 4   Open    3020 non-null   float64\n",
      " 5   Volume  3020 non-null   int64  \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 165.2+ KB\n",
      "None\n",
      "             Close         High          Low         Open        Volume\n",
      "count  3020.000000  3020.000000  3020.000000  3020.000000  3.020000e+03\n",
      "mean    197.754324   199.647567   195.655555   197.648166  6.106539e+07\n",
      "std     100.438180   101.211180    99.590004   100.468176  5.038725e+07\n",
      "min      33.870834    34.711709    33.825574    34.297226  7.164500e+06\n",
      "25%     129.782692   131.199307   128.742168   129.978691  2.499982e+07\n",
      "50%     175.049347   176.652968   173.310852   174.942352  4.459055e+07\n",
      "75%     252.844566   255.030832   249.251713   252.349872  8.235035e+07\n",
      "max     464.002502   464.786500   460.926110   463.446749  4.265100e+08\n",
      "Ticker     object\n",
      "Close     float64\n",
      "High      float64\n",
      "Low       float64\n",
      "Open      float64\n",
      "Volume      int64\n",
      "dtype: object\n",
      "Ticker    0\n",
      "Close     0\n",
      "High      0\n",
      "Low       0\n",
      "Open      0\n",
      "Volume    0\n",
      "dtype: int64\n",
      "2019-01-02 00:00:00\n",
      "2024-12-31 00:00:00\n",
      "Row False\n",
      "col False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "appl = pd.read_csv('/home/micheal/Documents/Python_Library/RL_Optimization_Portfolio/data/raw/AAPL_daily.CSV', parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "msft = pd.read_csv('/home/micheal/Documents/Python_Library/RL_Optimization_Portfolio/data/raw/MSFT_daily.CSV', parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "\n",
    "\n",
    "df = pd.concat([appl, msft])\n",
    "\n",
    "\n",
    "is_multi_index = isinstance(df.index, pd.MultiIndex)  \n",
    "is_multi_col= isinstance(df.columns, pd.MultiIndex)\n",
    "\n",
    "df = df.drop(columns=['Unnamed: 0']).copy()\n",
    "\n",
    "print (df.head())\n",
    "print (df.columns)\n",
    "print (df[['Ticker']])\n",
    "print (df.info())\n",
    "print (df.describe())\n",
    "print (df.dtypes)\n",
    "print (df.isna().sum())\n",
    "print (df.index.to_series().min())\n",
    "print (df.index.to_series().max())\n",
    "print ('Row', is_multi_index)\n",
    "print ('col', is_multi_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Ticker      Close       High        Low       Open     Volume  \\\n",
      "Date                                                                       \n",
      "2019-01-03   AAPL  33.870834  34.711709  33.825574  34.297226  365248800   \n",
      "2019-01-04   AAPL  35.316757  35.385840  34.254350  34.428241  234428400   \n",
      "2019-01-07   AAPL  35.238152  35.452541  34.754589  35.421573  219111200   \n",
      "2019-01-08   AAPL  35.909897  36.164781  35.378693  35.626428  164101200   \n",
      "2019-01-09   AAPL  36.519714  36.810329  35.643110  36.038533  180396400   \n",
      "\n",
      "            LogReturn  LogReturn_Z  \n",
      "Date                                \n",
      "2019-01-03  -0.104924    -5.465055  \n",
      "2019-01-04   0.041803     2.087049  \n",
      "2019-01-07  -0.002228    -0.179263  \n",
      "2019-01-08   0.018884     0.907367  \n",
      "2019-01-09   0.016839     0.802147  \n",
      "Ticker         0\n",
      "Close          0\n",
      "High           0\n",
      "Low            0\n",
      "Open           0\n",
      "Volume         0\n",
      "LogReturn      0\n",
      "LogReturn_Z    0\n",
      "dtype: int64\n",
      "Empty DataFrame\n",
      "Columns: [Ticker, Close, High, Low, Open, Volume, LogReturn, LogReturn_Z]\n",
      "Index: []\n",
      "           Ticker       Close        High         Low        Open    Volume  \\\n",
      "Date                                                                          \n",
      "2024-12-24   MSFT  437.647369  437.916355  432.527071  432.985301   7164500   \n",
      "2024-12-26   MSFT  436.432068  439.251246  434.957756  437.398354   8194200   \n",
      "2024-12-27   MSFT  428.881104  433.553144  424.717120  432.935523  18117700   \n",
      "2024-12-30   MSFT  423.202911  425.912495  420.284140  424.428211  13158700   \n",
      "2024-12-31   MSFT  419.885681  425.095662  419.048902  424.468070  13246500   \n",
      "\n",
      "            LogReturn  LogReturn_Z  \n",
      "Date                                \n",
      "2024-12-24   0.009330     0.456481  \n",
      "2024-12-26  -0.002781    -0.206004  \n",
      "2024-12-27  -0.017453    -1.008597  \n",
      "2024-12-30  -0.013328    -0.782952  \n",
      "2024-12-31  -0.007869    -0.484353  \n"
     ]
    }
   ],
   "source": [
    "df['LogReturn'] = df.groupby('Ticker')['Close'].transform(lambda x: np.log(x / x.shift(1)))\n",
    "\n",
    "df.dropna(subset=['LogReturn'], inplace=True)\n",
    "\n",
    "df['LogReturn_Z'] = df.groupby('Ticker')['LogReturn'].transform(lambda x: (x - x.mean())/ x.std())\n",
    "\n",
    "print (df.head())\n",
    "print (df.isna().sum())\n",
    "print (df[df.isna().any(axis=1)])\n",
    "print (df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df.to_csv('/home/micheal/Documents/Python_Library/RL_Optimization_Portfolio/data/processed/AP_MS_daily.CSV')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Ticker      Close       High        Low       Open     Volume  \\\n",
      "Date                                                                       \n",
      "2019-01-03   AAPL  33.870834  34.711709  33.825574  34.297226  365248800   \n",
      "2019-01-04   AAPL  35.316757   35.38584   34.25435  34.428241  234428400   \n",
      "2019-01-07   AAPL  35.238152  35.452541  34.754589  35.421573  219111200   \n",
      "2019-01-08   AAPL  35.909897  36.164781  35.378693  35.626428  164101200   \n",
      "2019-01-09   AAPL  36.519714  36.810329   35.64311  36.038533  180396400   \n",
      "\n",
      "            LogReturn  LogReturn_Z  \n",
      "Date                                \n",
      "2019-01-03  -0.104924    -5.465055  \n",
      "2019-01-04   0.041803     2.087049  \n",
      "2019-01-07  -0.002228    -0.179263  \n",
      "2019-01-08   0.018884     0.907367  \n",
      "2019-01-09   0.016839     0.802147  \n",
      "Ticker                category\n",
      "Close          double[pyarrow]\n",
      "High           double[pyarrow]\n",
      "Low            double[pyarrow]\n",
      "Open           double[pyarrow]\n",
      "Volume         uint32[pyarrow]\n",
      "LogReturn      double[pyarrow]\n",
      "LogReturn_Z    double[pyarrow]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "addres = '/home/micheal/Documents/Python_Library/RL_Optimization_Portfolio/data/processed/AP_MS_daily.CSV'\n",
    "raw = pd.read_csv(addres, parse_dates=['Date'], index_col='Date', engine='pyarrow', dtype_backend='pyarrow')\n",
    "\n",
    "def shrinking_ints (df):\n",
    "    mapping = {}\n",
    "    for col in df.dtypes [df.dtypes=='int64[pyarrow]'].index:\n",
    "        max_ = df[col].max()\n",
    "        min_ = df[col].min()\n",
    "        if min_ < 0:\n",
    "            continue\n",
    "        elif max_ < 255:\n",
    "            mapping[col] = 'uint8[pyarrow]'\n",
    "        elif max_ <65_535:\n",
    "            mapping[col] = 'uint16[pyarrow]'\n",
    "        elif max_ < 4294967295:\n",
    "            mapping[col] = 'uint32[pyarrow]'\n",
    "    return df.astype(mapping)\n",
    "\n",
    "def clean(df):\n",
    "    return (df\n",
    "    .assign(**df.select_dtypes('string').replace('', 'Missing').astype('category'))\n",
    "    .pipe(shrinking_ints)\n",
    "    )\n",
    "    \n",
    "df = clean(raw)\n",
    "\n",
    "print (df.head())\n",
    "print (df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6, Total Value: 1003.19\n",
      "Step 7, Total Value: 1013.09\n",
      "Step 8, Total Value: 997.74\n",
      "Step 9, Total Value: 997.74\n",
      "Step 10, Total Value: 985.62\n",
      "Step 11, Total Value: 991.46\n",
      "Step 12, Total Value: 997.55\n",
      "Step 13, Total Value: 997.55\n",
      "Step 14, Total Value: 997.55\n",
      "Step 15, Total Value: 997.55\n"
     ]
    }
   ],
   "source": [
    "env = PortfolioEnv(df, window_size=5)\n",
    "\n",
    "state = env.reset()\n",
    "\n",
    "for _ in range(10):\n",
    "    action = env.action_space.sample()\n",
    "    next_step, reward, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    \n",
    "    if done:\n",
    "        print('Episode finished.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/micheal/anaconda3/lib/python3.12/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.08    |\n",
      "|    explained_variance | -46.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.0637  |\n",
      "|    value_loss         | 0.00414  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.08    |\n",
      "|    explained_variance | -1.57    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.0379   |\n",
      "|    value_loss         | 0.00265  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.09    |\n",
      "|    explained_variance | -1.63    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.018    |\n",
      "|    value_loss         | 0.000432 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.08    |\n",
      "|    explained_variance | -0.809   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.0146   |\n",
      "|    value_loss         | 0.000487 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.05    |\n",
      "|    explained_variance | -66.1    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -0.194   |\n",
      "|    value_loss         | 0.0356   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 120      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.03    |\n",
      "|    explained_variance | -6.2     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.0182   |\n",
      "|    value_loss         | 0.00052  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.879   |\n",
      "|    explained_variance | -7.98    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.0715   |\n",
      "|    value_loss         | 0.00247  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.03    |\n",
      "|    explained_variance | -10.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.0394   |\n",
      "|    value_loss         | 0.00392  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 119      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.06    |\n",
      "|    explained_variance | -0.325   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.0141  |\n",
      "|    value_loss         | 0.000301 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.04    |\n",
      "|    explained_variance | -5.51    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -0.00313 |\n",
      "|    value_loss         | 0.000235 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.85    |\n",
      "|    explained_variance | -133     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.0612  |\n",
      "|    value_loss         | 0.0113   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1       |\n",
      "|    explained_variance | -227     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.012   |\n",
      "|    value_loss         | 0.000726 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.908   |\n",
      "|    explained_variance | -23.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.0423   |\n",
      "|    value_loss         | 0.00648  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.931   |\n",
      "|    explained_variance | -0.823   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.0648   |\n",
      "|    value_loss         | 0.00226  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.03    |\n",
      "|    explained_variance | -0.193   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.0128   |\n",
      "|    value_loss         | 0.000405 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.879   |\n",
      "|    explained_variance | -21      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.0536   |\n",
      "|    value_loss         | 0.00808  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.02    |\n",
      "|    explained_variance | -22.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.064    |\n",
      "|    value_loss         | 0.00548  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.04    |\n",
      "|    explained_variance | -1.98    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.0141  |\n",
      "|    value_loss         | 0.000344 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.972   |\n",
      "|    explained_variance | 0.0761   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.0461   |\n",
      "|    value_loss         | 0.0018   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.926   |\n",
      "|    explained_variance | -0.434   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.0304   |\n",
      "|    value_loss         | 0.00108  |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7c5cca602b40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = DummyVecEnv([lambda: PortfolioEnv(df, window_size=5)])\n",
    "\n",
    "model = A2C('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
